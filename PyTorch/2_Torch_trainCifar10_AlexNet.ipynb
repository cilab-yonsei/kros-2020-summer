{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2_Torch_trainCifar10_AlexNet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "omu4-vsanK3e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torch.backends.cudnn as cudnn\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import sklearn.metrics as skl\n",
        "\n",
        "\n",
        "\n",
        "# Define CNN Architecture\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "epochs = 100\n",
        "\n",
        "\n",
        "#Visualizing CIFAR 10\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data',download=True)\n",
        "datanum = len(trainset)\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "fig = plt.figure()\n",
        "ims = np.random.randint(datanum, size=15)\n",
        "\n",
        "for i in range(15):\n",
        "    subplot = fig.add_subplot(3,5, i+1)\n",
        "    subplot.set_xticks([])\n",
        "    subplot.set_yticks([])\n",
        "    PILimg, label = trainset[ims[i]]\n",
        "    subplot.set_title(\"%s\" %classes[label])\n",
        "    subplot.imshow(PILimg)\n",
        "\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "# Data\n",
        "print('==> Preparing data..')\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=128, shuffle=False, num_workers=2)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhtVibcI9PsE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Model\n",
        "\n",
        "class AlexNet(nn.Module):\n",
        "\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(AlexNet, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 96, kernel_size=11, stride=4, padding=5),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
        "            nn.Conv2d(96, 256, kernel_size=5, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
        "            nn.Conv2d(256, 384, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(384, 384, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            # nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(256 * 2 * 2, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(4096, num_classes),\n",
        "            #nn.Softmax()\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "print('==> Building model..')\n",
        "net = AlexNet()\n",
        "\n",
        "net = net.to(device)\n",
        "if device == 'cuda':\n",
        "    net = torch.nn.DataParallel(net)\n",
        "    cudnn.benchmark = True\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=10, verbose=True)\n",
        "\n",
        "\n",
        "\n",
        "# Training\n",
        "def train(epoch):\n",
        "    print('\\nEpoch: %d' % epoch)\n",
        "    print('\\nTrain:')\n",
        "    net.train()\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    print_time = -1\n",
        "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "        if time.time()-print_time > 1 or print_time == -1 or batch_idx+1 == len(trainloader):\n",
        "            print('[%3d/%3d] | Loss: %.3f | Acc: %.3f%% (%d/%d)'%(\n",
        "                batch_idx+1, len(trainloader), train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
        "            \n",
        "            print_time = time.time()\n",
        "\n",
        "\n",
        "def test(epoch):\n",
        "    print('\\nTest:')\n",
        "    global best_acc\n",
        "    net.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    print_time = -1\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            test_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "            if time.time()-print_time > 1 or print_time == -1 or batch_idx+1 == len(testloader):\n",
        "                print('[%3d/%3d] | Loss: %.3f | Acc: %.3f%% (%d/%d)'%(\n",
        "                    batch_idx+1, len(testloader), test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
        "                \n",
        "                print_time = time.time()\n",
        "                \n",
        "\n",
        "for epoch in range(epochs):\n",
        "    train(epoch)\n",
        "    test(epoch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TztY64oz1_jJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_confusion_matrix(cm, classes,normalize=False,title='Confusion matrix',cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    #print(cm)\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            plt.text(j, i, format(cm[i, j], fmt),horizontalalignment=\"center\",color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZ4FmLMHpER2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ylabel = []\n",
        "yhatlabel = []\n",
        "\n",
        "for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "    inputs, targets = inputs.to(device), targets.to(device)\n",
        "    outputs = net(inputs)\n",
        "    _, predicted = outputs.max(1)\n",
        "    ylabel = np.concatenate((ylabel, targets.cpu().numpy()))\n",
        "    yhatlabel = np.concatenate((yhatlabel, predicted.cpu().numpy()))\n",
        "# Compute confusion matrix\n",
        "cnf_matrix = skl.confusion_matrix(ylabel, yhatlabel)\n",
        "np.set_printoptions(precision=2)\n",
        "is_correct = (ylabel == yhatlabel)\n",
        "acc = np.sum(is_correct * 1) / len(is_correct)\n",
        "print('accuracy:%.5f' %acc)\n",
        "\n",
        "\n",
        "# Plot non-normalized confusion matrix\n",
        "plt.figure()\n",
        "plot_confusion_matrix(cnf_matrix, classes=classes,\n",
        "                  title='Confusion matrix, without normalization')\n",
        "\n",
        "# Plot normalized confusion matrix\n",
        "plt.figure()\n",
        "plot_confusion_matrix(cnf_matrix, classes=classes, normalize=True,\n",
        "                  title='Normalized confusion matrix')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}